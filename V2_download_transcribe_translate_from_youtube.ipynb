{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dddmmm789/youtube_dubbing_tool/blob/main/V2_download_transcribe_translate_from_youtube.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTsK5faw_kEM"
      },
      "source": [
        "# YouTube Video Download Service\n",
        "\n",
        "This notebook:\n",
        " - downloads YouTube videos directly to Google Drive\n",
        " - extracts audio\n",
        " - split audio to vocals and backgroung music\n",
        " - transcrive vocals\n",
        " - translate vocals\n",
        " - createa a vocals json file\n",
        "\n",
        " * all the files will be stored in google drive\n",
        "\n",
        "## Setup\n",
        "First, we'll install required packages and mount Google Drive:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EYbFGzn_mUU",
        "outputId": "7ec299d9-6ecf-46b3-b3a7-6f26dd05fa3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# @title Mounting Google Drive\n",
        "# Set up steprs to downloading the video - press play\n",
        "##video download from youtube - set up 1\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2Mm04nV_qJE",
        "outputId": "729034fa-1592-4522-b2aa-79e7894867f8",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2024.11.18-py3-none-any.whl.metadata (172 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/172.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”\u001b[0m \u001b[32m163.8/172.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m172.1/172.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2024.11.18-py3-none-any.whl (3.2 MB)\n",
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[32m2.6/3.2 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp\n",
            "Successfully installed yt-dlp-2024.11.18\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ],
      "source": [
        "# @title Play this step and wait to see the message: Successfully installed python-dotenv-1.0.1\n",
        "#video download from youtube - set up 2\n",
        "!pip install yt-dlp\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEm04nw6_qtd",
        "outputId": "36cf8701-6008-4bf8-b610-6131aacb5de8",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Successfully imported all required libraries!\n",
            "Ready to download YouTube videos to Google Drive.\n"
          ]
        }
      ],
      "source": [
        "# @title Import required libraries\n",
        "# video download from youtube - Import required libraries\n",
        "import os\n",
        "import yt_dlp\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "# Print success message\n",
        "print(\"âœ… Successfully imported all required libraries!\")\n",
        "print(\"Ready to download YouTube videos to Google Drive.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmlykS42WxRC",
        "outputId": "0e75943f-1081-45e9-9747-dfed8e2b8248",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Enter YouTube URL to download (press Enter for default): https://www.youtube.com/shorts/GFV4J50dfRE\n",
            "ğŸš€ Starting download process...\n",
            "ğŸ“ URL: https://www.youtube.com/shorts/GFV4J50dfRE\n",
            "ğŸ“ Target folder: downloads\n",
            "ğŸ”„ Initializing download...\n",
            "[youtube] Extracting URL: https://www.youtube.com/shorts/GFV4J50dfRE\n",
            "[youtube] GFV4J50dfRE: Downloading webpage\n",
            "[youtube] GFV4J50dfRE: Downloading ios player API JSON\n",
            "[youtube] GFV4J50dfRE: Downloading mweb player API JSON\n",
            "[youtube] GFV4J50dfRE: Downloading player b46bb280\n",
            "[youtube] GFV4J50dfRE: Downloading m3u8 information\n",
            "[youtube] Extracting URL: https://www.youtube.com/shorts/GFV4J50dfRE\n",
            "[youtube] GFV4J50dfRE: Downloading webpage\n",
            "[youtube] GFV4J50dfRE: Downloading ios player API JSON\n",
            "[youtube] GFV4J50dfRE: Downloading mweb player API JSON\n",
            "[youtube] GFV4J50dfRE: Downloading m3u8 information\n",
            "[info] GFV4J50dfRE: Downloading 1 format(s): 401+140\n",
            "[download] Destination: /content/temp_video/Baby_Trains_For_Olympics!_ğŸ’ªğŸ”¥_@podgorka_.f401.mp4\n",
            "[download] 100% of   30.99MiB in 00:00:01 at 26.63MiB/s  \n",
            "[download] Destination: /content/temp_video/Baby_Trains_For_Olympics!_ğŸ’ªğŸ”¥_@podgorka_.f140.m4a\n",
            "[download] 100% of  522.82KiB in 00:00:00 at 7.39MiB/s   \n",
            "[Merger] Merging formats into \"/content/temp_video/Baby_Trains_For_Olympics!_ğŸ’ªğŸ”¥_@podgorka_.mp4\"\n",
            "Deleting original file /content/temp_video/Baby_Trains_For_Olympics!_ğŸ’ªğŸ”¥_@podgorka_.f401.mp4 (pass -k to keep)\n",
            "Deleting original file /content/temp_video/Baby_Trains_For_Olympics!_ğŸ’ªğŸ”¥_@podgorka_.f140.m4a (pass -k to keep)\n",
            "\n",
            "âœ¨ Download Summary:\n",
            "ğŸ“ Original title: Baby Trains For Olympics! ğŸ’ªğŸ”¥ @podgorka_\n",
            "ğŸ“ Safe title: Baby_Trains_For_Olympics!_ğŸ’ªğŸ”¥_@podgorka_\n",
            "ğŸ“ Temporary local path: /content/temp_video/Baby_Trains_For_Olympics!_ğŸ’ªğŸ”¥_@podgorka_.mp4\n",
            "ğŸ“Š File size: 31.5 MB\n",
            "\n",
            "ğŸ“¤ Uploading to Google Drive...\n",
            "â³ Uploaded: 3%\n",
            "â³ Uploaded: 6%\n",
            "â³ Uploaded: 9%\n",
            "â³ Uploaded: 12%\n",
            "â³ Uploaded: 15%\n",
            "â³ Uploaded: 19%\n",
            "â³ Uploaded: 22%\n",
            "â³ Uploaded: 25%\n",
            "â³ Uploaded: 28%\n",
            "â³ Uploaded: 31%\n",
            "â³ Uploaded: 34%\n",
            "â³ Uploaded: 38%\n",
            "â³ Uploaded: 41%\n",
            "â³ Uploaded: 44%\n",
            "â³ Uploaded: 47%\n",
            "â³ Uploaded: 50%\n",
            "â³ Uploaded: 53%\n",
            "â³ Uploaded: 57%\n",
            "â³ Uploaded: 60%\n",
            "â³ Uploaded: 63%\n",
            "â³ Uploaded: 66%\n",
            "â³ Uploaded: 69%\n",
            "â³ Uploaded: 72%\n",
            "â³ Uploaded: 76%\n",
            "â³ Uploaded: 79%\n",
            "â³ Uploaded: 82%\n",
            "â³ Uploaded: 85%\n",
            "â³ Uploaded: 88%\n",
            "â³ Uploaded: 92%\n",
            "â³ Uploaded: 95%\n",
            "â³ Uploaded: 98%\n",
            "\n",
            "âœ… Upload verified:\n",
            "ğŸ“ Name: Baby Trains For Olympics! ğŸ’ªğŸ”¥ @podgorka_.mp4\n",
            "ğŸ“Œ ID: 16qTsXciCKL50pUDOyCT-7jUp5emu6IkA\n",
            "ğŸ”— Direct link: https://drive.google.com/file/d/16qTsXciCKL50pUDOyCT-7jUp5emu6IkA/view?usp=drivesdk\n",
            "\n",
            "ğŸ§¹ Temporary file cleaned up\n",
            "\n",
            "ğŸ‰ Final Result:\n",
            "âœ… Video successfully uploaded to Google Drive\n",
            "ğŸ“‚ Folder link: https://drive.google.com/drive/folders/1etobnRBWhgj3s9HtqUbjUvWizKqs3dFV\n",
            "ğŸ¥ Video link: https://drive.google.com/file/d/16qTsXciCKL50pUDOyCT-7jUp5emu6IkA/view\n",
            "\n",
            "âš ï¸ Note: It might take a few minutes for the file to appear in the folder view\n"
          ]
        }
      ],
      "source": [
        "# @title Download the video from Youtube\n",
        "import os\n",
        "import yt_dlp\n",
        "from google.colab import drive\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "def sanitize_filename(filename):\n",
        "    \"\"\"Remove or replace problematic characters in filename.\"\"\"\n",
        "    # Replace problematic characters with underscores\n",
        "    invalid_chars = ['?', 'ï¼', 'ï¼Ÿ', '|', ':', '/', '\\\\', '*', '\"', '<', '>', '|']\n",
        "    for char in invalid_chars:\n",
        "        filename = filename.replace(char, '_')\n",
        "    # Replace multiple spaces/underscores with single underscore\n",
        "    filename = '_'.join(filter(None, filename.split()))\n",
        "    return filename\n",
        "\n",
        "def download_video(youtube_url, folder_id):\n",
        "    \"\"\"Download a video from YouTube and upload to Google Drive.\"\"\"\n",
        "    print(f\"ğŸš€ Starting download process...\")\n",
        "    print(f\"ğŸ“ URL: {youtube_url}\")\n",
        "\n",
        "    # Set up Google Drive service\n",
        "    credentials = GoogleCredentials.get_application_default()\n",
        "    drive_service = build('drive', 'v3', credentials=credentials)\n",
        "\n",
        "    # Verify folder exists\n",
        "    try:\n",
        "        folder = drive_service.files().get(fileId=folder_id).execute()\n",
        "        print(f\"ğŸ“ Target folder: {folder.get('name', 'Unknown folder')}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error accessing folder: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "    # Temporary local directory\n",
        "    temp_dir = '/content/temp_video'\n",
        "    os.makedirs(temp_dir, exist_ok=True)\n",
        "\n",
        "    # Configure yt-dlp options with sanitized output template\n",
        "    ydl_opts = {\n",
        "        'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best',\n",
        "        'outtmpl': f'{temp_dir}/%(title)s.%(ext)s',\n",
        "        'quiet': False,\n",
        "        'no_warnings': False,\n",
        "        'progress': True,\n",
        "        'restrictfilenames': True,  # Restrict filenames to ASCII characters\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        print(\"ğŸ”„ Initializing download...\")\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            # Get video info first\n",
        "            info = ydl.extract_info(youtube_url, download=False)\n",
        "            video_title = info['title']\n",
        "            safe_title = sanitize_filename(video_title)\n",
        "\n",
        "            # Update output template with safe filename\n",
        "            ydl_opts['outtmpl'] = f'{temp_dir}/{safe_title}.%(ext)s'\n",
        "\n",
        "            # Download with updated options\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl2:\n",
        "                ydl2.download([youtube_url])\n",
        "\n",
        "            # Construct the expected output path\n",
        "            local_path = os.path.join(temp_dir, f\"{safe_title}.mp4\")\n",
        "\n",
        "            print(\"\\nâœ¨ Download Summary:\")\n",
        "            print(f\"ğŸ“ Original title: {video_title}\")\n",
        "            print(f\"ğŸ“ Safe title: {safe_title}\")\n",
        "            print(f\"ğŸ“ Temporary local path: {local_path}\")\n",
        "\n",
        "            # Verify local file exists and get size\n",
        "            if not os.path.exists(local_path):\n",
        "                print(f\"âŒ Error: Downloaded file not found at {local_path}\")\n",
        "                print(\"ğŸ“‚ Directory contents:\")\n",
        "                for file in os.listdir(temp_dir):\n",
        "                    print(f\"- {file}\")\n",
        "                return False\n",
        "\n",
        "            file_size = os.path.getsize(local_path) / (1024 * 1024)  # Convert to MB\n",
        "            print(f\"ğŸ“Š File size: {file_size:.1f} MB\")\n",
        "\n",
        "            # Upload to Google Drive\n",
        "            print(\"\\nğŸ“¤ Uploading to Google Drive...\")\n",
        "            file_metadata = {\n",
        "                'name': f\"{video_title}.mp4\",  # Use original title for Drive\n",
        "                'parents': [folder_id],\n",
        "                'mimeType': 'video/mp4'\n",
        "            }\n",
        "\n",
        "            media = MediaFileUpload(\n",
        "                local_path,\n",
        "                mimetype='video/mp4',\n",
        "                resumable=True,\n",
        "                chunksize=1024*1024\n",
        "            )\n",
        "\n",
        "            # Create the file with progress tracking\n",
        "            request = drive_service.files().create(\n",
        "                body=file_metadata,\n",
        "                media_body=media,\n",
        "                fields='id,name,mimeType,size,parents'\n",
        "            )\n",
        "\n",
        "            response = None\n",
        "            while response is None:\n",
        "                status, response = request.next_chunk()\n",
        "                if status:\n",
        "                    print(f\"â³ Uploaded: {int(status.progress() * 100)}%\")\n",
        "\n",
        "            # Verify upload\n",
        "            file_id = response.get('id')\n",
        "            uploaded_file = drive_service.files().get(\n",
        "                fileId=file_id,\n",
        "                fields='id,name,size,parents,webViewLink'\n",
        "            ).execute()\n",
        "\n",
        "            print(\"\\nâœ… Upload verified:\")\n",
        "            print(f\"ğŸ“ Name: {uploaded_file.get('name')}\")\n",
        "            print(f\"ğŸ“Œ ID: {uploaded_file.get('id')}\")\n",
        "            print(f\"ğŸ”— Direct link: {uploaded_file.get('webViewLink')}\")\n",
        "\n",
        "            # Clean up temporary file\n",
        "            os.remove(local_path)\n",
        "            print(\"\\nğŸ§¹ Temporary file cleaned up\")\n",
        "\n",
        "            return uploaded_file.get('id')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"\\nâŒ Upload Failed!\")\n",
        "        print(f\"âš ï¸ Error: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False\n",
        "\n",
        "# Mount Google Drive and authenticate\n",
        "drive.mount('/content/drive')\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Set up the specific Google Drive folder ID\n",
        "FOLDER_ID = \"1etobnRBWhgj3s9HtqUbjUvWizKqs3dFV\"\n",
        "\n",
        "# Get URL and start download\n",
        "DEFAULT_URL = \"https://www.youtube.com/watch?v=AdBzzpq3xV4\"\n",
        "test_url = input(\"Enter YouTube URL to download (press Enter for default): \").strip()\n",
        "\n",
        "# Use default URL if no input provided\n",
        "if not test_url:\n",
        "    test_url = DEFAULT_URL\n",
        "    print(f\"Using default URL: {DEFAULT_URL}\")\n",
        "\n",
        "file_id = download_video(test_url, FOLDER_ID)\n",
        "if file_id:\n",
        "    print(f\"\\nğŸ‰ Final Result:\")\n",
        "    print(f\"âœ… Video successfully uploaded to Google Drive\")\n",
        "    print(f\"ğŸ“‚ Folder link: https://drive.google.com/drive/folders/{FOLDER_ID}\")\n",
        "    print(f\"ğŸ¥ Video link: https://drive.google.com/file/d/{file_id}/view\")\n",
        "    print(\"\\nâš ï¸ Note: It might take a few minutes for the file to appear in the folder view\")\n",
        "else:\n",
        "    print(\"\\nâŒ Upload failed. Please check the error messages above.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfVtr0TPDuLm",
        "outputId": "13d16b49-59c8-445c-e366-86fce6c5c6f0",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Files in the folder:\n",
            "Baby Trains For Olympics! ğŸ’ªğŸ”¥ @podgorka_.mp4 (ID: 1xtcKw3p8QxuhoJjGO2nYBMUmbVy-97M9)\n",
            "Kunjungilah Ibumu, Dia Pasti Sangat Bahagia ğŸ˜Š (ID: 1fzYlxpEDCeXQk3S2eavJsITLa-fsRiEO)\n",
            "Who is the Quietest Loud?? ğŸ¤« | The Loud House (ID: 1_I1-jxi2kxQCYaC50_vxDbAdZsk_4BpY)\n",
            "Lady Gaga, Bruno Mars - Die With A Smile (ID: 1dtIDjkvh48mWSMUTLBImagDjncrBUvQ3)\n",
            "×’××¨ ×”×™×©×¨×“×•×ª ××•×œ×¡×˜××¨×¡ - ×¡×™×¤×•×¨ ×”×’×¨×¨ ×©×œ ×“×Ÿ ×•××™×¨×™×ª! (ID: 1hykZ2dvme9bQQCdc4l32BMB-UWyWB2VH)\n",
            "extracted_audio_stems (ID: 1zdpu0QpIC0DvD5rdqhde4bfZf7ZPlwKD)\n",
            "Lady Gaga, Bruno Mars - Die With A Smile (ID: 1mFUO_aqE8on0wvcjA0LCorcmCn0qyMQd)\n",
            "extracted_audio.wav (ID: 1LugVyKDVKmDFnyRYjs-QGOMrVt2sN5TX)\n",
            "extracted_audio.wav (ID: 1iIDgvvmCrLM08rYZgI51baiUG9phRION)\n",
            "The Internet is starting to Break - Here's Why..mp4 (ID: 1tFQsP55VrZRz0r_AcQ6pbd5xrs4_swir)\n",
            "Lady Gaga, Bruno Mars - Die With A Smile.mp4 (ID: 1bzw8zix-8MfyDebNQCYEA_bPw-hUfThB)\n",
            "Enter the ID of the video file to process (or press Enter for the last file): 1xtcKw3p8QxuhoJjGO2nYBMUmbVy-97M9\n",
            "Created new folder: Baby Trains For Olympics! ğŸ’ªğŸ”¥ @podgorka_\n",
            "Downloading video file to: /content/temp_audio/Baby Trains For Olympics! ğŸ’ªğŸ”¥ @podgorka_.mp4\n",
            "Download 100%.\n",
            "Extracting audio to: /content/temp_audio/Baby Trains For Olympics! ğŸ’ªğŸ”¥ @podgorka__audio.wav\n",
            "Uploading extracted audio to Google Drive...\n",
            "Moving original video to the new folder...\n",
            "Temporary files cleaned up.\n",
            "\n",
            "ğŸ“ File Locations:\n",
            "Folder: https://drive.google.com/drive/folders/1MJMWrDC4DAVkcrBjZmpgWhUsBUiLFU5t\n",
            "Original video: https://drive.google.com/file/d/1xtcKw3p8QxuhoJjGO2nYBMUmbVy-97M9/view\n",
            "Extracted audio: https://drive.google.com/file/d/1p9fBXHrrM8-GWGgp9hfr1QXm7N3Tzdgh/view\n",
            "\n",
            "ğŸ”— Main Google Drive folder: https://drive.google.com/drive/folders/1etobnRBWhgj3s9HtqUbjUvWizKqs3dFV\n"
          ]
        }
      ],
      "source": [
        "# @title Extract audio main\n",
        "#extract audio main\n",
        "import os\n",
        "import subprocess\n",
        "from google.colab import drive\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import io\n",
        "\n",
        "# Ensure Google Drive is mounted and authenticated\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Set up Google Drive service\n",
        "credentials = GoogleCredentials.get_application_default()\n",
        "drive_service = build('drive', 'v3', credentials=credentials)\n",
        "\n",
        "def download_file_from_drive(file_id, destination):\n",
        "    \"\"\"Download a file from Google Drive.\"\"\"\n",
        "    request = drive_service.files().get_media(fileId=file_id)\n",
        "    fh = io.FileIO(destination, 'wb')\n",
        "    downloader = MediaIoBaseDownload(fh, request)\n",
        "    done = False\n",
        "    while done is False:\n",
        "        status, done = downloader.next_chunk()\n",
        "        print(f\"Download {int(status.progress() * 100)}%.\")\n",
        "\n",
        "def extract_audio(input_file, output_file):\n",
        "    \"\"\"Extract audio from video file using ffmpeg.\"\"\"\n",
        "    command = [\n",
        "        'ffmpeg',\n",
        "        '-i', input_file,\n",
        "        '-vn',  # Disable video\n",
        "        '-acodec', 'pcm_s16le',  # Audio codec\n",
        "        '-ar', '44100',  # Audio sampling rate\n",
        "        '-ac', '2',  # Number of audio channels\n",
        "        output_file\n",
        "    ]\n",
        "    subprocess.run(command, check=True)\n",
        "\n",
        "def create_folder_in_drive(folder_name, parent_folder_id):\n",
        "    \"\"\"Create a new folder in Google Drive.\"\"\"\n",
        "    file_metadata = {\n",
        "        'name': folder_name,\n",
        "        'mimeType': 'application/vnd.google-apps.folder',\n",
        "        'parents': [parent_folder_id]\n",
        "    }\n",
        "    file = drive_service.files().create(body=file_metadata, fields='id').execute()\n",
        "    return file.get('id')\n",
        "\n",
        "def upload_to_drive(file_path, folder_id):\n",
        "    \"\"\"Upload a file to Google Drive.\"\"\"\n",
        "    file_name = os.path.basename(file_path)\n",
        "    file_metadata = {'name': file_name, 'parents': [folder_id]}\n",
        "    media = MediaFileUpload(file_path, resumable=True)\n",
        "    file = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
        "    return file.get('id')\n",
        "\n",
        "def move_file_in_drive(file_id, new_folder_id):\n",
        "    \"\"\"Move a file to a different folder in Google Drive.\"\"\"\n",
        "    file = drive_service.files().get(fileId=file_id, fields='parents').execute()\n",
        "    previous_parents = \",\".join(file.get('parents'))\n",
        "    file = drive_service.files().update(\n",
        "        fileId=file_id,\n",
        "        addParents=new_folder_id,\n",
        "        removeParents=previous_parents,\n",
        "        fields='id, parents'\n",
        "    ).execute()\n",
        "\n",
        "# Set up directories\n",
        "FOLDER_ID = \"1etobnRBWhgj3s9HtqUbjUvWizKqs3dFV\"\n",
        "TEMP_DIR = '/content/temp_audio'\n",
        "os.makedirs(TEMP_DIR, exist_ok=True)\n",
        "\n",
        "# List files in the Google Drive folder\n",
        "results = drive_service.files().list(q=f\"'{FOLDER_ID}' in parents\", fields=\"files(id, name)\").execute()\n",
        "files = results.get('files', [])\n",
        "\n",
        "if not files:\n",
        "    print('No files found in the specified folder.')\n",
        "else:\n",
        "    print(\"Files in the folder:\")\n",
        "    for file in files:\n",
        "        print(f\"{file['name']} (ID: {file['id']})\")\n",
        "\n",
        "    # Ask user to select a file\n",
        "    file_id = input(\"Enter the ID of the video file to process (or press Enter for the last file): \").strip()\n",
        "    if not file_id and files:\n",
        "        file_id = files[-1]['id']\n",
        "        print(f\"Using the last file: {files[-1]['name']}\")\n",
        "\n",
        "    if file_id:\n",
        "        # Get video details\n",
        "        video_file = drive_service.files().get(fileId=file_id, fields='name').execute()\n",
        "        video_name = os.path.splitext(video_file['name'])[0]  # Remove extension\n",
        "\n",
        "        # Create a new folder in Drive\n",
        "        new_folder_id = create_folder_in_drive(video_name, FOLDER_ID)\n",
        "        print(f\"Created new folder: {video_name}\")\n",
        "\n",
        "        # Download the selected file\n",
        "        input_file = os.path.join(TEMP_DIR, f'{video_name}.mp4')\n",
        "        print(f\"Downloading video file to: {input_file}\")\n",
        "        download_file_from_drive(file_id, input_file)\n",
        "\n",
        "        # Extract audio\n",
        "        output_file = os.path.join(TEMP_DIR, f'{video_name}_audio.wav')\n",
        "        print(f\"Extracting audio to: {output_file}\")\n",
        "        extract_audio(input_file, output_file)\n",
        "\n",
        "        # Upload extracted audio to the new folder\n",
        "        print(\"Uploading extracted audio to Google Drive...\")\n",
        "        audio_file_id = upload_to_drive(output_file, new_folder_id)\n",
        "\n",
        "        # Move the original video to the new folder\n",
        "        print(\"Moving original video to the new folder...\")\n",
        "        move_file_in_drive(file_id, new_folder_id)\n",
        "\n",
        "        # Clean up\n",
        "        os.remove(input_file)\n",
        "        os.remove(output_file)\n",
        "        print(\"Temporary files cleaned up.\")\n",
        "\n",
        "        # Provide links and information\n",
        "        print(\"\\nğŸ“ File Locations:\")\n",
        "        print(f\"Folder: https://drive.google.com/drive/folders/{new_folder_id}\")\n",
        "        print(f\"Original video: https://drive.google.com/file/d/{file_id}/view\")\n",
        "        print(f\"Extracted audio: https://drive.google.com/file/d/{audio_file_id}/view\")\n",
        "        print(f\"\\nğŸ”— Main Google Drive folder: https://drive.google.com/drive/folders/{FOLDER_ID}\")\n",
        "\n",
        "    else:\n",
        "        print(\"No file selected for processing.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGeMddbJGRyA",
        "outputId": "1df75424-2c2c-4e96-fff4-30fdafffe382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: spleeter in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: ffmpeg-python<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from spleeter) (0.2.0)\n",
            "Requirement already satisfied: httpx<0.20.0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]<0.20.0,>=0.19.0->spleeter) (0.19.0)\n",
            "Requirement already satisfied: norbert<0.3.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from spleeter) (0.2.1)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from spleeter) (1.5.3)\n",
            "Requirement already satisfied: tensorflow<2.10.0,>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from spleeter) (2.9.3)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from spleeter) (0.3.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python<0.3.0,>=0.2.0->spleeter) (1.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (2024.8.30)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.10/dist-packages (from httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (3.4.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (1.3.1)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from rfc3986[idna2008]<2,>=1.3->httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (1.5.0)\n",
            "Requirement already satisfied: httpcore<0.14.0,>=0.13.3 in /usr/local/lib/python3.10/dist-packages (from httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (0.13.7)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]<0.20.0,>=0.19.0->spleeter) (4.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from norbert<0.3.0,>=0.2.1->spleeter) (1.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.3.0->spleeter) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.3.0->spleeter) (2024.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.3.0->spleeter) (1.26.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (1.12)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (1.68.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (3.12.1)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (2.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (24.2)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (2.9.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (0.37.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (2.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (1.16.0)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.4.0,>=0.3.2->spleeter) (7.1.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.10.0,>=2.5.0->spleeter) (0.45.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]<0.20.0,>=0.19.0->spleeter) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]<0.20.0,>=0.19.0->spleeter) (4.0.0)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.14.0,>=0.13.3->httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (0.12.0)\n",
            "Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore<0.14.0,>=0.13.3->httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore<0.14.0,>=0.13.3->httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore<0.14.0,>=0.13.3->httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (1.2.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter) (1.3.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter) (2.2.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "# @title Split file to audio and vocals (setting up libraries - SPLEETER)\n",
        "#spleeter set up\n",
        "\n",
        "from google.colab import drive, auth\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload\n",
        "from google.auth import default\n",
        "import io\n",
        "import shutil\n",
        "import subprocess\n",
        "\n",
        "# Mount Drive and install Spleeter\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!pip install spleeter\n",
        "\n",
        "class AudioSplitter:\n",
        "    def __init__(self):\n",
        "        # Authenticate\n",
        "        auth.authenticate_user()\n",
        "\n",
        "        # Get credentials\n",
        "        creds, _ = default()\n",
        "\n",
        "        # Build the Drive service\n",
        "        self.drive_service = build('drive', 'v3', credentials=creds)\n",
        "\n",
        "        # Set the specific folder ID and create temp directories\n",
        "        self.TARGET_FOLDER_ID = \"1etobnRBWhgj3s9HtqUbjUvWizKqs3dFV\"\n",
        "        self.TEMP_DIR = '/content/temp_processing'\n",
        "        os.makedirs(self.TEMP_DIR, exist_ok=True)\n",
        "\n",
        "    def list_files_recursive(self, folder_id=None):\n",
        "        \"\"\"List all WAV files in the folder and its subfolders\"\"\"\n",
        "        if folder_id is None:\n",
        "            folder_id = self.TARGET_FOLDER_ID\n",
        "\n",
        "        try:\n",
        "            # Query for all WAV files in this folder and subfolders\n",
        "            query = f\"'{folder_id}' in parents and (mimeType contains 'audio/wav' or mimeType contains 'audio/x-wav')\"\n",
        "            results = self.drive_service.files().list(\n",
        "                q=query,\n",
        "                fields=\"files(id, name, modifiedTime, parents)\",\n",
        "                orderBy='modifiedTime desc'\n",
        "            ).execute()\n",
        "\n",
        "            files = results.get('files', [])\n",
        "\n",
        "            # Get subfolders\n",
        "            folder_query = f\"'{folder_id}' in parents and mimeType='application/vnd.google-apps.folder'\"\n",
        "            folder_results = self.drive_service.files().list(\n",
        "                q=folder_query,\n",
        "                fields=\"files(id)\"\n",
        "            ).execute()\n",
        "\n",
        "            # Recursively search subfolders\n",
        "            for folder in folder_results.get('files', []):\n",
        "                files.extend(self.list_files_recursive(folder['id']))\n",
        "\n",
        "            return files\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error listing files: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def process_audio(self, file_id, file_name, parent_folder_id):\n",
        "        \"\"\"Process audio file with Spleeter\"\"\"\n",
        "        try:\n",
        "            input_path = os.path.join(self.TEMP_DIR, file_name)\n",
        "            output_dir = os.path.join(self.TEMP_DIR, 'output')\n",
        "            os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "            # Download file\n",
        "            print(f\"ğŸ“¥ Downloading {file_name}...\")\n",
        "            request = self.drive_service.files().get_media(fileId=file_id)\n",
        "            with open(input_path, 'wb') as f:\n",
        "                downloader = MediaIoBaseDownload(f, request)\n",
        "                done = False\n",
        "                while not done:\n",
        "                    status, done = downloader.next_chunk()\n",
        "                    print(f\"Download {int(status.progress() * 100)}%\")\n",
        "\n",
        "            # Process with Spleeter\n",
        "            print(\"ğŸ”„ Processing with Spleeter...\")\n",
        "            subprocess.run([\n",
        "                'spleeter', 'separate',\n",
        "                '-p', 'spleeter:2stems',\n",
        "                '-o', output_dir,\n",
        "                input_path\n",
        "            ], check=True)\n",
        "\n",
        "            # Upload results\n",
        "            base_name = os.path.splitext(file_name)[0]\n",
        "            stems_path = os.path.join(output_dir, base_name)\n",
        "\n",
        "            # Create stems folder in the same location as the original file\n",
        "            stems_folder_name = f\"{base_name}_stems\"\n",
        "            folder_metadata = {\n",
        "                'name': stems_folder_name,\n",
        "                'mimeType': 'application/vnd.google-apps.folder',\n",
        "                'parents': [parent_folder_id]\n",
        "            }\n",
        "            stems_folder = self.drive_service.files().create(\n",
        "                body=folder_metadata,\n",
        "                fields='id'\n",
        "            ).execute()\n",
        "\n",
        "            # Upload each stem\n",
        "            for stem in ['vocals', 'accompaniment']:\n",
        "                stem_file = os.path.join(stems_path, f\"{stem}.wav\")\n",
        "                if os.path.exists(stem_file):\n",
        "                    print(f\"ğŸ“¤ Uploading {stem}.wav...\")\n",
        "                    file_metadata = {\n",
        "                        'name': f\"{stem}.wav\",\n",
        "                        'parents': [stems_folder.get('id')]\n",
        "                    }\n",
        "                    media = MediaFileUpload(stem_file, resumable=True)\n",
        "                    self.drive_service.files().create(\n",
        "                        body=file_metadata,\n",
        "                        media_body=media,\n",
        "                        fields='id'\n",
        "                    ).execute()\n",
        "\n",
        "            # Cleanup\n",
        "            shutil.rmtree(self.TEMP_DIR)\n",
        "            os.makedirs(self.TEMP_DIR, exist_ok=True)\n",
        "\n",
        "            print(\"âœ¨ Processing complete!\")\n",
        "            return stems_folder.get('id')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error: {str(e)}\")\n",
        "            return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_OMwcDCOB1y",
        "outputId": "20f4e216-c67b-4ed6-fa2d-238179d0632d",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸµ Available Audio Files:\n",
            "1. extracted_audio.wav (Modified: 2024-11-27 14:46:30)\n",
            "2. extracted_audio.wav (Modified: 2024-11-27 14:43:42)\n",
            "3. Baby Trains For Olympics! ğŸ’ªğŸ”¥ @podgorka__audio.wav (Modified: 2024-12-02 12:12:56)\n",
            "4. Kunjungilah Ibumu, Dia Pasti Sangat Bahagia ğŸ˜Š_audio.wav (Modified: 2024-12-02 04:58:39)\n",
            "5. accompaniment.wav (Modified: 2024-12-02 05:01:41)\n",
            "6. vocals.wav (Modified: 2024-12-02 05:01:40)\n",
            "7. Who is the Quietest Loud?? ğŸ¤« | The Loud House_audio.wav (Modified: 2024-11-28 06:09:59)\n",
            "8. accompaniment.wav (Modified: 2024-11-28 06:15:33)\n",
            "9. vocals.wav (Modified: 2024-11-28 06:15:31)\n",
            "10. Lady Gaga, Bruno Mars - Die With A Smile_audio.wav (Modified: 2024-11-28 05:52:54)\n",
            "11. ×’××¨ ×”×™×©×¨×“×•×ª ××•×œ×¡×˜××¨×¡ - ×¡×™×¤×•×¨ ×”×’×¨×¨ ×©×œ ×“×Ÿ ×•××™×¨×™×ª!_audio.wav (Modified: 2024-11-27 16:00:42)\n",
            "12. accompaniment.wav (Modified: 2024-11-27 16:01:54)\n",
            "13. vocals.wav (Modified: 2024-11-27 16:01:52)\n",
            "14. accompaniment.wav (Modified: 2024-11-27 15:24:59)\n",
            "15. vocals.wav (Modified: 2024-11-27 15:24:57)\n",
            "16. Lady Gaga, Bruno Mars - Die With A Smile_audio.wav (Modified: 2024-11-27 14:48:25)\n",
            "17. accompaniment.wav (Modified: 2024-11-27 15:28:26)\n",
            "18. vocals.wav (Modified: 2024-11-27 15:28:24)\n",
            "\n",
            "Enter the number of the file to process (or 'q' to quit): 3\n",
            "\n",
            "ğŸ¯ Processing: Baby Trains For Olympics! ğŸ’ªğŸ”¥ @podgorka__audio.wav\n",
            "ğŸ“¥ Downloading Baby Trains For Olympics! ğŸ’ªğŸ”¥ @podgorka__audio.wav...\n",
            "Download 100%\n",
            "ğŸ”„ Processing with Spleeter...\n",
            "ğŸ“¤ Uploading vocals.wav...\n",
            "ğŸ“¤ Uploading accompaniment.wav...\n",
            "âœ¨ Processing complete!\n",
            "\n",
            "âœ… Success! You can find the stems here:\n",
            "ğŸ”— https://drive.google.com/drive/folders/1pdOfxAvTqXZs0rkrYHX_iF2LKsMbccjH\n"
          ]
        }
      ],
      "source": [
        "# @title Spleeter Main\n",
        "# Initialize the splitter\n",
        "splitter = AudioSplitter()\n",
        "\n",
        "# List all WAV files in the folder and subfolders\n",
        "files = splitter.list_files_recursive()\n",
        "\n",
        "if files:\n",
        "    print(\"\\nğŸµ Available Audio Files:\")\n",
        "    for idx, file in enumerate(files, 1):\n",
        "        modified_time = datetime.fromisoformat(file['modifiedTime'].replace('Z', '+00:00')).strftime('%Y-%m-%d %H:%M:%S')\n",
        "        print(f\"{idx}. {file['name']} (Modified: {modified_time})\")\n",
        "\n",
        "    while True:\n",
        "        choice = input(\"\\nEnter the number of the file to process (or 'q' to quit): \").strip()\n",
        "        if choice.lower() == 'q':\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            idx = int(choice) - 1\n",
        "            if 0 <= idx < len(files):\n",
        "                selected_file = files[idx]\n",
        "                print(f\"\\nğŸ¯ Processing: {selected_file['name']}\")\n",
        "\n",
        "                stems_folder_id = splitter.process_audio(\n",
        "                    selected_file['id'],\n",
        "                    selected_file['name'],\n",
        "                    selected_file['parents'][0]\n",
        "                )\n",
        "\n",
        "                if stems_folder_id:\n",
        "                    print(\"\\nâœ… Success! You can find the stems here:\")\n",
        "                    print(f\"ğŸ”— https://drive.google.com/drive/folders/{stems_folder_id}\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"âŒ Invalid number. Please try again.\")\n",
        "        except ValueError:\n",
        "            print(\"âŒ Please enter a valid number.\")\n",
        "else:\n",
        "    print(\"No WAV files found in the folder or its subfolders.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymWlj2W7RZJI",
        "outputId": "3d7027ac-397f-4dc3-f57c-c367e125def6",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.6)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting triton>=2.0.0 (from openai-whisper)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803320 sha256=9e3cc646ce8e329e1cfc4a0cb189e950b777fe75fde5c826f509c62dec204cdc\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/4a/1f/d1c4bf3b9133c8168fe617ed979cab7b14fe381d059ffb9d83\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: triton, tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20240930 tiktoken-0.8.0 triton-3.1.0\n"
          ]
        }
      ],
      "source": [
        "# @title Transcribing the original vocals - OpenAI Whispper set up\n",
        "#transcription set up\n",
        "\n",
        "from google.colab import drive, auth\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "from google.oauth2.credentials import Credentials\n",
        "from googleapiclient.discovery import build\n",
        "from google.auth import default\n",
        "from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload\n",
        "import io\n",
        "\n",
        "# Mount Google Drive if not already mounted\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Install whisper\n",
        "!pip install -U openai-whisper\n",
        "\n",
        "# Now import whisper after installation\n",
        "import whisper\n",
        "\n",
        "class TranscriptionService:\n",
        "    def __init__(self):\n",
        "        print(\"Initializing TranscriptionService...\")  # Debug print\n",
        "\n",
        "        # Authenticate and set up Google Drive\n",
        "        auth.authenticate_user()\n",
        "        creds, _ = default()\n",
        "        self.drive_service = build('drive', 'v3', credentials=creds)\n",
        "\n",
        "        # Target folder ID\n",
        "        self.TARGET_FOLDER_ID = \"1etobnRBWhgj3s9HtqUbjUvWizKqs3dFV\"\n",
        "\n",
        "        # Initialize Whisper model\n",
        "        print(\"Loading Whisper model...\")\n",
        "        self.model = whisper.load_model(\"base\")\n",
        "        print(\"âœ… Model loaded!\")\n",
        "\n",
        "        # Set up working directory\n",
        "        self.temp_dir = '/content/temp_transcription'\n",
        "        os.makedirs(self.temp_dir, exist_ok=True)\n",
        "\n",
        "        # Add language options\n",
        "        print(\"Setting up language options...\")  # Debug print\n",
        "        self.LANGUAGE_OPTIONS = {\n",
        "            \"auto\": \"Auto-detect\",\n",
        "            \"en\": \"English\",\n",
        "            \"es\": \"Spanish\",\n",
        "            \"fr\": \"French\",\n",
        "            \"de\": \"German\",\n",
        "            \"it\": \"Italian\",\n",
        "            \"pt\": \"Portuguese\",\n",
        "            \"nl\": \"Dutch\",\n",
        "            \"pl\": \"Polish\",\n",
        "            \"ru\": \"Russian\",\n",
        "            \"ar\": \"Arabic\",\n",
        "            \"zh\": \"Chinese\",\n",
        "            \"ja\": \"Japanese\",\n",
        "            \"ko\": \"Korean\",\n",
        "            \"hi\": \"Hindi\",\n",
        "            \"ID\": \"Indonesian\",\n",
        "            \"he\": \"Hebrew\"\n",
        "        }\n",
        "        print(\"Language options set up successfully\")  # Debug print\n",
        "\n",
        "    def get_vocal_files(self):\n",
        "        \"\"\"Get all vocals.wav files from stems folders\"\"\"\n",
        "        try:\n",
        "            # First get all stems folders\n",
        "            stems_query = f\"mimeType='application/vnd.google-apps.folder' and name contains '_stems'\"\n",
        "            folders = self.drive_service.files().list(\n",
        "                q=stems_query,\n",
        "                orderBy='modifiedTime desc',\n",
        "                fields=\"files(id, name, modifiedTime)\"\n",
        "            ).execute().get('files', [])\n",
        "\n",
        "            vocal_files = []\n",
        "            for folder in folders:\n",
        "                # Look for vocals.wav in each stems folder\n",
        "                vocals_query = f\"'{folder['id']}' in parents and name='vocals.wav'\"\n",
        "                vocals = self.drive_service.files().list(\n",
        "                    q=vocals_query,\n",
        "                    fields=\"files(id, name)\"\n",
        "                ).execute().get('files', [])\n",
        "\n",
        "                if vocals:\n",
        "                    vocal_file = vocals[0]\n",
        "                    vocal_file['folder_name'] = folder['name']\n",
        "                    vocal_file['modifiedTime'] = folder['modifiedTime']\n",
        "                    vocal_files.append(vocal_file)\n",
        "\n",
        "            return vocal_files\n",
        "        except Exception as e:\n",
        "            print(f\"Error listing files: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def transcribe_audio(self, file_id, file_name, folder_name):\n",
        "        \"\"\"Download and transcribe the audio file\"\"\"\n",
        "        try:\n",
        "            print(\"Starting transcription process...\")  # Debug print\n",
        "            print(f\"Language options available: {self.LANGUAGE_OPTIONS}\")  # Debug print\n",
        "\n",
        "            # Download file\n",
        "            input_path = os.path.join(self.temp_dir, file_name)\n",
        "            request = self.drive_service.files().get_media(fileId=file_id)\n",
        "\n",
        "            print(f\"ğŸ“¥ Downloading {folder_name} - vocals...\")\n",
        "            with open(input_path, 'wb') as f:\n",
        "                downloader = MediaIoBaseDownload(f, request)\n",
        "                done = False\n",
        "                while not done:\n",
        "                    status, done = downloader.next_chunk()\n",
        "                    print(f\"Download {int(status.progress() * 100)}%\")\n",
        "\n",
        "            # Ask for language\n",
        "            print(\"\\nğŸŒ Available languages:\")\n",
        "            for code, name in self.LANGUAGE_OPTIONS.items():\n",
        "                print(f\"{code}: {name}\")\n",
        "\n",
        "            language = input(\"\\nEnter language code (or press Enter for auto-detection): \").strip().lower()\n",
        "\n",
        "            # Validate language input\n",
        "            if language and language not in self.LANGUAGE_OPTIONS:\n",
        "                print(\"âŒ Invalid language code, falling back to auto-detection\")\n",
        "                language = None\n",
        "\n",
        "            # Transcribe\n",
        "            print(\"ğŸ¯ Transcribing audio...\")\n",
        "            transcription_options = {}\n",
        "            if language and language != \"auto\":\n",
        "                transcription_options[\"language\"] = language\n",
        "                print(f\"Using specified language: {self.LANGUAGE_OPTIONS[language]}\")\n",
        "            else:\n",
        "                print(\"Using language auto-detection...\")\n",
        "\n",
        "            result = self.model.transcribe(input_path, **transcription_options)\n",
        "\n",
        "            # Add detected language to output\n",
        "            detected_language = result.get('language', 'unknown')\n",
        "            print(f\"ğŸ” Detected language: {self.LANGUAGE_OPTIONS.get(detected_language, detected_language)}\")\n",
        "\n",
        "            # Create transcription file with additional metadata\n",
        "            transcript = {\n",
        "                'text': result['text'],\n",
        "                'segments': result['segments'],\n",
        "                'language': detected_language,\n",
        "                'specified_language': language if language and language != \"auto\" else None,\n",
        "                'timestamp': datetime.now().isoformat()\n",
        "            }\n",
        "\n",
        "            # Save locally first\n",
        "            json_path = os.path.join(self.temp_dir, 'transcription.json')\n",
        "            with open(json_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(transcript, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "            # Upload to Drive in same folder as vocals\n",
        "            parent_folder_id = self.drive_service.files().get(\n",
        "                fileId=file_id,\n",
        "                fields='parents'\n",
        "            ).execute()['parents'][0]\n",
        "\n",
        "            file_metadata = {\n",
        "                'name': 'transcription.json',\n",
        "                'parents': [parent_folder_id]\n",
        "            }\n",
        "\n",
        "            media = MediaFileUpload(\n",
        "                json_path,\n",
        "                mimetype='application/json',\n",
        "                resumable=True\n",
        "            )\n",
        "\n",
        "            print(\"ğŸ“¤ Uploading transcription...\")\n",
        "            uploaded_file = self.drive_service.files().create(\n",
        "                body=file_metadata,\n",
        "                media_body=media,\n",
        "                fields='id'\n",
        "            ).execute()\n",
        "\n",
        "            # Cleanup\n",
        "            os.remove(input_path)\n",
        "            os.remove(json_path)\n",
        "\n",
        "            return uploaded_file.get('id'), transcript\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error during transcription: {str(e)}\")\n",
        "            return None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpbGKTbtV32J",
        "outputId": "a08a65a1-59e4-4058-d79e-f0ca4f867c04",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing TranscriptionService...\n",
            "Loading Whisper model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139M/139M [00:01<00:00, 104MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model loaded!\n",
            "Setting up language options...\n",
            "Language options set up successfully\n",
            "\n",
            "ğŸµ Available Vocal Files:\n",
            "1. Baby Trains For Olympics! ğŸ’ªğŸ”¥ @podgorka__audio_stems (Modified: 2024-12-02 12:17:09)\n",
            "2. Kunjungilah Ibumu, Dia Pasti Sangat Bahagia ğŸ˜Š_audio_stems (Modified: 2024-12-02 05:01:38)\n",
            "3. Who is the Quietest Loud?? ğŸ¤« | The Loud House_audio_stems (Modified: 2024-11-28 06:15:29)\n",
            "4. ×’××¨ ×”×™×©×¨×“×•×ª ××•×œ×¡×˜××¨×¡ - ×¡×™×¤×•×¨ ×”×’×¨×¨ ×©×œ ×“×Ÿ ×•××™×¨×™×ª!_audio_stems (Modified: 2024-11-27 16:01:51)\n",
            "5. Lady Gaga, Bruno Mars - Die With A Smile_audio_stems (Modified: 2024-11-27 15:28:23)\n",
            "6. extracted_audio_stems (Modified: 2024-11-27 15:24:55)\n",
            "\n",
            "Enter the number of the file to process (or 'q' to quit): 1\n",
            "\n",
            "ğŸ¯ Processing: Baby Trains For Olympics! ğŸ’ªğŸ”¥ @podgorka__audio_stems\n",
            "Starting transcription process...\n",
            "Language options available: {'auto': 'Auto-detect', 'en': 'English', 'es': 'Spanish', 'fr': 'French', 'de': 'German', 'it': 'Italian', 'pt': 'Portuguese', 'nl': 'Dutch', 'pl': 'Polish', 'ru': 'Russian', 'ar': 'Arabic', 'zh': 'Chinese', 'ja': 'Japanese', 'ko': 'Korean', 'hi': 'Hindi', 'ID': 'Indonesian', 'he': 'Hebrew'}\n",
            "ğŸ“¥ Downloading Baby Trains For Olympics! ğŸ’ªğŸ”¥ @podgorka__audio_stems - vocals...\n",
            "Download 100%\n",
            "\n",
            "ğŸŒ Available languages:\n",
            "auto: Auto-detect\n",
            "en: English\n",
            "es: Spanish\n",
            "fr: French\n",
            "de: German\n",
            "it: Italian\n",
            "pt: Portuguese\n",
            "nl: Dutch\n",
            "pl: Polish\n",
            "ru: Russian\n",
            "ar: Arabic\n",
            "zh: Chinese\n",
            "ja: Japanese\n",
            "ko: Korean\n",
            "hi: Hindi\n",
            "ID: Indonesian\n",
            "he: Hebrew\n",
            "\n",
            "Enter language code (or press Enter for auto-detection): en\n",
            "ğŸ¯ Transcribing audio...\n",
            "Using specified language: English\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” Detected language: English\n",
            "ğŸ“¤ Uploading transcription...\n",
            "\n",
            "âœ… Success! Transcription complete!\n",
            "ğŸ”— Transcription file: https://drive.google.com/file/d/1gb6qG9aaYnRb2Cqphi4BJbA_8duoJhkJ/view\n",
            "\n",
            "ğŸ“ First few lines of transcription:\n",
            " This baby was already training for the Olympics at 6 months old. The older he got, the more skills he developed as he got stronger and stronger. At just 21 months old, he was already able to flip his...\n"
          ]
        }
      ],
      "source": [
        "# @title Transpcription Main\n",
        "#main transcription\n",
        "\n",
        "# Initialize the service\n",
        "transcriber = TranscriptionService()\n",
        "\n",
        "# Get list of vocal files\n",
        "vocal_files = transcriber.get_vocal_files()\n",
        "\n",
        "if vocal_files:\n",
        "    print(\"\\nğŸµ Available Vocal Files:\")\n",
        "    for idx, file in enumerate(vocal_files, 1):\n",
        "        modified_time = datetime.fromisoformat(file['modifiedTime'].replace('Z', '+00:00')).strftime('%Y-%m-%d %H:%M:%S')\n",
        "        print(f\"{idx}. {file['folder_name']} (Modified: {modified_time})\")\n",
        "\n",
        "    while True:\n",
        "        choice = input(\"\\nEnter the number of the file to process (or 'q' to quit): \").strip()\n",
        "        if choice.lower() == 'q':\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            idx = int(choice) - 1\n",
        "            if 0 <= idx < len(vocal_files):\n",
        "                selected_file = vocal_files[idx]\n",
        "                print(f\"\\nğŸ¯ Processing: {selected_file['folder_name']}\")\n",
        "\n",
        "                file_id, transcript = transcriber.transcribe_audio(\n",
        "                    selected_file['id'],\n",
        "                    selected_file['name'],\n",
        "                    selected_file['folder_name']\n",
        "                )\n",
        "\n",
        "                if file_id:\n",
        "                    print(\"\\nâœ… Success! Transcription complete!\")\n",
        "                    print(f\"ğŸ”— Transcription file: https://drive.google.com/file/d/{file_id}/view\")\n",
        "                    print(\"\\nğŸ“ First few lines of transcription:\")\n",
        "                    print(transcript['text'][:200] + \"...\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"âŒ Invalid number. Please try again.\")\n",
        "        except ValueError:\n",
        "            print(\"âŒ Please enter a valid number.\")\n",
        "else:\n",
        "    print(\"No vocal files found in stems folders.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IC8bjdBS_Q7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PE9BuCOX8UV"
      },
      "source": [
        "**Translation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vt6Y2npVajGJ",
        "outputId": "0e16dcb5-b821-4b24-98d5-5579c0371beb",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: deepl in /usr/local/lib/python3.10/dist-packages (1.20.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from deepl) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->deepl) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->deepl) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->deepl) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->deepl) (2024.8.30)\n",
            "Requirement already satisfied: googletrans==4.0.0-rc1 in /usr/local/lib/python3.10/dist-packages (4.0.0rc1)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.8.30)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.12.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n"
          ]
        }
      ],
      "source": [
        "# @title Translation with deepL and Google Translate as backup - set up\n",
        "from google.colab import drive, auth\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "from googleapiclient.discovery import build\n",
        "from google.auth import default\n",
        "from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload\n",
        "import io\n",
        "\n",
        "# Mount Google Drive if not already mounted\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Install required packages\n",
        "!pip install deepl\n",
        "!pip install googletrans==4.0.0-rc1\n",
        "\n",
        "# Import required libraries\n",
        "import deepl\n",
        "from googletrans import Translator\n",
        "\n",
        "class TranslationService:\n",
        "    def __init__(self, auth_key):\n",
        "        try:\n",
        "            # Initialize DeepL\n",
        "            self.deepl_translator = deepl.Translator(auth_key)\n",
        "            print(\"DeepL API connected successfully!\")\n",
        "            print(f\"Character usage: {self.deepl_translator.get_usage().character.count}/{self.deepl_translator.get_usage().character.limit}\")\n",
        "\n",
        "            # Initialize Google Translator as backup\n",
        "            self.google_translator = Translator()\n",
        "\n",
        "            # Authenticate and set up Google Drive\n",
        "            auth.authenticate_user()\n",
        "            creds, _ = default()\n",
        "            self.drive_service = build('drive', 'v3', credentials=creds)\n",
        "\n",
        "            # Set up working directory\n",
        "            self.temp_dir = '/content/temp_translation'\n",
        "            os.makedirs(self.temp_dir, exist_ok=True)\n",
        "\n",
        "            # Define supported languages\n",
        "            self.DEEPL_LANGUAGES = {\n",
        "                \"EN-US\": \"English (American)\",\n",
        "                \"EN-GB\": \"English (British)\",\n",
        "                \"ES\": \"Spanish\",\n",
        "                \"FR\": \"French\",\n",
        "                \"DE\": \"German\",\n",
        "                \"IT\": \"Italian\",\n",
        "                \"PT-PT\": \"Portuguese\",\n",
        "                \"RU\": \"Russian\",\n",
        "                \"JA\": \"Japanese\",\n",
        "                \"ZH\": \"Chinese\"\n",
        "            }\n",
        "\n",
        "            # Additional languages supported by Google Translate\n",
        "            self.GOOGLE_LANGUAGES = {\n",
        "                \"HE\": \"Hebrew\",\n",
        "                # Add other languages as needed\n",
        "            }\n",
        "\n",
        "            # Combine all supported languages\n",
        "            self.LANGUAGE_OPTIONS = {**self.DEEPL_LANGUAGES, **self.GOOGLE_LANGUAGES}\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error initializing translation services: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def translate_text(self, text, target_lang, source_lang=None):\n",
        "        \"\"\"Translate text using appropriate service\"\"\"\n",
        "        try:\n",
        "            # Handle deprecated EN code\n",
        "            if target_lang == \"EN\":\n",
        "                target_lang = \"EN-US\"  # Default to US English\n",
        "                print(\"Note: Using EN-US for English translation\")\n",
        "\n",
        "            # Use DeepL for supported languages (except when source is Hebrew)\n",
        "            if target_lang in self.DEEPL_LANGUAGES and source_lang != \"HE\":\n",
        "                result = self.deepl_translator.translate_text(text, target_lang=target_lang)\n",
        "                return result.text\n",
        "            # Fall back to Google Translate for Hebrew or other unsupported languages\n",
        "            else:\n",
        "                # Convert language codes for Google Translate\n",
        "                google_target_lang = target_lang.lower().split('-')[0]  # Convert EN-US to en, etc.\n",
        "                google_source_lang = source_lang.lower() if source_lang else 'auto'\n",
        "\n",
        "                print(f\"Using Google Translate: {google_source_lang} -> {google_target_lang}\")\n",
        "                result = self.google_translator.translate(\n",
        "                    text=text,\n",
        "                    dest=google_target_lang,\n",
        "                    src=google_source_lang\n",
        "                )\n",
        "                return result.text\n",
        "        except Exception as e:\n",
        "            print(f\"Translation error: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def list_transcription_files(self):\n",
        "        \"\"\"List all transcription.json files in the target folder\"\"\"\n",
        "        try:\n",
        "            query = f\"mimeType='application/json' and name contains 'transcription'\"\n",
        "            results = self.drive_service.files().list(\n",
        "                q=query,\n",
        "                orderBy='modifiedTime desc',\n",
        "                fields=\"files(id, name, modifiedTime, parents)\"\n",
        "            ).execute()\n",
        "\n",
        "            files = results.get('files', [])\n",
        "            if not files:\n",
        "                print(\"No transcription files found.\")\n",
        "                return []\n",
        "\n",
        "            # Filter files that are in our target folder structure\n",
        "            valid_files = []\n",
        "            for file in files:\n",
        "                try:\n",
        "                    parent = self.drive_service.files().get(\n",
        "                        fileId=file['parents'][0],\n",
        "                        fields=\"name, parents\"\n",
        "                    ).execute()\n",
        "                    if '_stems' in parent['name']:\n",
        "                        file['folder_name'] = parent['name']\n",
        "                        valid_files.append(file)\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "            return valid_files\n",
        "        except Exception as e:\n",
        "            print(f\"Error listing files: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def translate_transcription(self, file_id, file_name, folder_name, target_lang, source_lang=None):\n",
        "        \"\"\"Download, translate, and upload the transcription file\"\"\"\n",
        "        try:\n",
        "            # Download file\n",
        "            input_path = os.path.join(self.temp_dir, file_name)\n",
        "            request = self.drive_service.files().get_media(fileId=file_id)\n",
        "\n",
        "            print(f\"ğŸ“¥ Downloading {folder_name} - transcription...\")\n",
        "            with open(input_path, 'wb') as f:\n",
        "                downloader = MediaIoBaseDownload(f, request)\n",
        "                done = False\n",
        "                while not done:\n",
        "                    status, done = downloader.next_chunk()\n",
        "                    print(f\"Download {int(status.progress() * 100)}%\")\n",
        "\n",
        "            # Load transcription\n",
        "            with open(input_path, 'r', encoding='utf-8') as f:\n",
        "                transcript = json.load(f)\n",
        "\n",
        "            # Determine which translation service to use\n",
        "            service_name = \"DeepL\" if target_lang in self.DEEPL_LANGUAGES and source_lang != \"HE\" else \"Google Translate\"\n",
        "            print(f\"ğŸŒ Using {service_name} for translation to {self.LANGUAGE_OPTIONS[target_lang]}...\")\n",
        "\n",
        "            # Translate each segment\n",
        "            translated_segments = []\n",
        "            total_segments = len(transcript['segments'])\n",
        "\n",
        "            for idx, segment in enumerate(transcript['segments'], 1):\n",
        "                print(f\"Translating segment {idx}/{total_segments}...\")\n",
        "                translated_text = self.translate_text(\n",
        "                    segment['text'],\n",
        "                    target_lang,\n",
        "                    source_lang\n",
        "                )\n",
        "                translated_segments.append({\n",
        "                    \"id\": segment[\"id\"],\n",
        "                    \"source_text\": segment[\"text\"],\n",
        "                    \"translated_text\": translated_text,\n",
        "                    \"start\": segment[\"start\"],\n",
        "                    \"end\": segment[\"end\"],\n",
        "                    \"words\": segment.get(\"words\", [])  # Use an empty list if \"words\" is missing\n",
        "                })\n",
        "\n",
        "            # Create translated transcription file\n",
        "            translated_transcript = {\n",
        "                \"metadata\": {\n",
        "                    \"source_language\": source_lang or transcript.get(\"language\", \"unknown\"),\n",
        "                    \"target_language\": target_lang,\n",
        "                    \"translation_service\": service_name,\n",
        "                    \"timestamp\": datetime.now().isoformat()\n",
        "                },\n",
        "                \"segments\": translated_segments\n",
        "            }\n",
        "\n",
        "            # Save locally first\n",
        "            translated_file_name = f\"transcription_{target_lang.lower()}.json\"\n",
        "            json_path = os.path.join(self.temp_dir, translated_file_name)\n",
        "            with open(json_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(translated_transcript, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "            # Upload to Drive in same folder as original transcription\n",
        "            parent_folder_id = self.drive_service.files().get(\n",
        "                fileId=file_id,\n",
        "                fields='parents'\n",
        "            ).execute()['parents'][0]\n",
        "\n",
        "            file_metadata = {\n",
        "                'name': translated_file_name,\n",
        "                'parents': [parent_folder_id]\n",
        "            }\n",
        "\n",
        "            media = MediaFileUpload(\n",
        "                json_path,\n",
        "                mimetype='application/json',\n",
        "                resumable=True\n",
        "            )\n",
        "\n",
        "            print(\"ğŸ“¤ Uploading translated transcription...\")\n",
        "            uploaded_file = self.drive_service.files().create(\n",
        "                body=file_metadata,\n",
        "                media_body=media,\n",
        "                fields='id'\n",
        "            ).execute()\n",
        "\n",
        "            # Get folder link\n",
        "            folder_link = f\"https://drive.google.com/drive/folders/{parent_folder_id}\"\n",
        "\n",
        "            # Cleanup\n",
        "            os.remove(input_path)\n",
        "            os.remove(json_path)\n",
        "\n",
        "            return uploaded_file.get('id'), translated_transcript, folder_link\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error during translation: {str(e)}\")\n",
        "            return None, None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZ400M4_B41M",
        "outputId": "e254ef28-6f75-4add-a086-da390d850b9f",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DeepL API connected successfully!\n",
            "Character usage: 7618/500000\n",
            "\n",
            "ğŸ“„ Available Transcription Files:\n",
            "1. Baby Trains For Olympics! ğŸ’ªğŸ”¥ @podgorka__audio_stems (Modified: 2024-12-02 12:21:08)\n",
            "2. Kunjungilah Ibumu, Dia Pasti Sangat Bahagia ğŸ˜Š_audio_stems (Modified: 2024-12-02 05:11:29)\n",
            "3. Kunjungilah Ibumu, Dia Pasti Sangat Bahagia ğŸ˜Š_audio_stems (Modified: 2024-12-02 05:03:18)\n",
            "4. Who is the Quietest Loud?? ğŸ¤« | The Loud House_audio_stems (Modified: 2024-11-28 06:24:15)\n",
            "5. Who is the Quietest Loud?? ğŸ¤« | The Loud House_audio_stems (Modified: 2024-11-28 06:21:51)\n",
            "6. ×’××¨ ×”×™×©×¨×“×•×ª ××•×œ×¡×˜××¨×¡ - ×¡×™×¤×•×¨ ×”×’×¨×¨ ×©×œ ×“×Ÿ ×•××™×¨×™×ª!_audio_stems (Modified: 2024-11-27 16:54:01)\n",
            "7. ×’××¨ ×”×™×©×¨×“×•×ª ××•×œ×¡×˜××¨×¡ - ×¡×™×¤×•×¨ ×”×’×¨×¨ ×©×œ ×“×Ÿ ×•××™×¨×™×ª!_audio_stems (Modified: 2024-11-27 16:52:30)\n",
            "8. ×’××¨ ×”×™×©×¨×“×•×ª ××•×œ×¡×˜××¨×¡ - ×¡×™×¤×•×¨ ×”×’×¨×¨ ×©×œ ×“×Ÿ ×•××™×¨×™×ª!_audio_stems (Modified: 2024-11-27 16:44:26)\n",
            "9. ×’××¨ ×”×™×©×¨×“×•×ª ××•×œ×¡×˜××¨×¡ - ×¡×™×¤×•×¨ ×”×’×¨×¨ ×©×œ ×“×Ÿ ×•××™×¨×™×ª!_audio_stems (Modified: 2024-11-27 16:34:39)\n",
            "10. ×’××¨ ×”×™×©×¨×“×•×ª ××•×œ×¡×˜××¨×¡ - ×¡×™×¤×•×¨ ×”×’×¨×¨ ×©×œ ×“×Ÿ ×•××™×¨×™×ª!_audio_stems (Modified: 2024-11-27 16:04:04)\n",
            "11. Lady Gaga, Bruno Mars - Die With A Smile_audio_stems (Modified: 2024-11-27 15:58:57)\n",
            "12. extracted_audio_stems (Modified: 2024-11-27 15:46:22)\n",
            "13. Lady Gaga, Bruno Mars - Die With A Smile_audio_stems (Modified: 2024-11-27 15:43:37)\n",
            "\n",
            "Enter the number of the file to translate (or 'q' to quit): 1\n",
            "\n",
            "ğŸ¯ Selected: Baby Trains For Olympics! ğŸ’ªğŸ”¥ @podgorka__audio_stems\n",
            "\n",
            "ğŸŒ Available languages:\n",
            "\n",
            "DeepL supported languages:\n",
            "EN-US: English (American)\n",
            "EN-GB: English (British)\n",
            "ES: Spanish\n",
            "FR: French\n",
            "DE: German\n",
            "IT: Italian\n",
            "PT-PT: Portuguese\n",
            "RU: Russian\n",
            "JA: Japanese\n",
            "ZH: Chinese\n",
            "\n",
            "Additional languages (via Google Translate):\n",
            "HE: Hebrew\n",
            "\n",
            "Enter source language code (or press Enter for auto-detection): en-gb\n",
            "Enter target language code (for English, use EN-US or EN-GB): pt-pt\n",
            "\n",
            "Translating from EN-GB to PT-PT...\n",
            "ğŸ“¥ Downloading Baby Trains For Olympics! ğŸ’ªğŸ”¥ @podgorka__audio_stems - transcription...\n",
            "Download 100%\n",
            "ğŸŒ Using DeepL for translation to Portuguese...\n",
            "Translating segment 1/7...\n",
            "Translating segment 2/7...\n",
            "Translating segment 3/7...\n",
            "Translating segment 4/7...\n",
            "Translating segment 5/7...\n",
            "Translating segment 6/7...\n",
            "Translating segment 7/7...\n",
            "ğŸ“¤ Uploading translated transcription...\n",
            "\n",
            "âœ… Success! Translation complete!\n",
            "ğŸ”— Translated file: https://drive.google.com/file/d/15SWIP0ATQHz3FljhyWsC_430PK5W7Dtd/view\n",
            "ğŸ“‚ Folder link: https://drive.google.com/drive/folders/1pdOfxAvTqXZs0rkrYHX_iF2LKsMbccjH\n",
            "\n",
            "ğŸ“ First segment translation:\n",
            "Original:  This baby was already training for the Olympics at 6 months old.\n",
            "Translated:  Este bebÃ© jÃ¡ estava a treinar para os Jogos OlÃ­mpicos aos 6 meses de idade.\n"
          ]
        }
      ],
      "source": [
        "# @title Translation Run - json output\n",
        "# Initialize the service with DeepL API key\n",
        "auth_key = \"bd006995-e700-4b10-8534-92668f452fbf:fx\"\n",
        "translator = TranslationService(auth_key)\n",
        "\n",
        "# Get list of transcription files\n",
        "transcription_files = translator.list_transcription_files()\n",
        "\n",
        "if transcription_files:\n",
        "    print(\"\\nğŸ“„ Available Transcription Files:\")\n",
        "    for idx, file in enumerate(transcription_files, 1):\n",
        "        modified_time = datetime.fromisoformat(file['modifiedTime'].replace('Z', '+00:00')).strftime('%Y-%m-%d %H:%M:%S')\n",
        "        print(f\"{idx}. {file['folder_name']} (Modified: {modified_time})\")\n",
        "\n",
        "    # First, select the file\n",
        "    while True:\n",
        "        choice = input(\"\\nEnter the number of the file to translate (or 'q' to quit): \").strip()\n",
        "        if choice.lower() == 'q':\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            idx = int(choice) - 1\n",
        "            if 0 <= idx < len(transcription_files):\n",
        "                selected_file = transcription_files[idx]\n",
        "                print(f\"\\nğŸ¯ Selected: {selected_file['folder_name']}\")\n",
        "\n",
        "                # Show available languages\n",
        "                print(\"\\nğŸŒ Available languages:\")\n",
        "                print(\"\\nDeepL supported languages:\")\n",
        "                print(\"EN-US: English (American)\")\n",
        "                print(\"EN-GB: English (British)\")\n",
        "                for code, name in translator.DEEPL_LANGUAGES.items():\n",
        "                    if not code.startswith(\"EN\"):  # Skip English as we've already shown it\n",
        "                        print(f\"{code}: {name}\")\n",
        "                print(\"\\nAdditional languages (via Google Translate):\")\n",
        "                for code, name in translator.GOOGLE_LANGUAGES.items():\n",
        "                    print(f\"{code}: {name}\")\n",
        "\n",
        "                # Language selection loop\n",
        "                while True:\n",
        "                    # Get source and target languages\n",
        "                    source_lang = input(\"\\nEnter source language code (or press Enter for auto-detection): \").strip().upper()\n",
        "                    if source_lang == \"\":\n",
        "                        source_lang = None\n",
        "                    elif source_lang not in translator.LANGUAGE_OPTIONS:\n",
        "                        print(\"âŒ Invalid source language code. Please try again.\")\n",
        "                        continue\n",
        "\n",
        "                    target_lang = input(\"Enter target language code (for English, use EN-US or EN-GB): \").strip().upper()\n",
        "                    if target_lang not in translator.LANGUAGE_OPTIONS:\n",
        "                        print(\"âŒ Invalid target language code. Please try again.\")\n",
        "                        continue\n",
        "\n",
        "                    print(f\"\\nTranslating from {source_lang if source_lang else 'auto-detected'} to {target_lang}...\")\n",
        "\n",
        "                    file_id, translated_transcript, folder_link = translator.translate_transcription(\n",
        "                        selected_file['id'],\n",
        "                        selected_file['name'],\n",
        "                        selected_file['folder_name'],\n",
        "                        target_lang,\n",
        "                        source_lang\n",
        "                    )\n",
        "\n",
        "                    if file_id:\n",
        "                        print(\"\\nâœ… Success! Translation complete!\")\n",
        "                        print(f\"ğŸ”— Translated file: https://drive.google.com/file/d/{file_id}/view\")\n",
        "                        print(f\"ğŸ“‚ Folder link: {folder_link}\")\n",
        "                        print(\"\\nğŸ“ First segment translation:\")\n",
        "                        first_segment = translated_transcript['segments'][0]\n",
        "                        print(f\"Original: {first_segment['source_text']}\")\n",
        "                        print(f\"Translated: {first_segment['translated_text']}\")\n",
        "                        break  # Break the language selection loop\n",
        "                break  # Break the file selection loop\n",
        "            else:\n",
        "                print(\"âŒ Invalid number. Please try again.\")\n",
        "        except ValueError:\n",
        "            print(\"âŒ Please enter a valid number.\")\n",
        "else:\n",
        "    print(\"No transcription files found.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjYpAWSx5PgQitSrXvFt5r",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}